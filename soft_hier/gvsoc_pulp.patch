diff --git a/pulp/floonoc/floonoc.cpp b/pulp/floonoc/floonoc.cpp
index 668a863..0d77e2d 100644
--- a/pulp/floonoc/floonoc.cpp
+++ b/pulp/floonoc/floonoc.cpp
@@ -36,6 +36,7 @@ FlooNoc::FlooNoc(vp::ComponentConf &config)
     this->dim_x = get_js_config()->get_int("dim_x");
     this->dim_y = get_js_config()->get_int("dim_y");
     this->router_input_queue_size = get_js_config()->get_int("router_input_queue_size");
+    this->atomics = get_js_config()->get_int("atomics");
 
     // Reserve the array for the target. We may have one target at each node.
     this->targets.resize(this->dim_x * this->dim_y);
diff --git a/pulp/floonoc/floonoc.hpp b/pulp/floonoc/floonoc.hpp
index 644696a..0a087a5 100644
--- a/pulp/floonoc/floonoc.hpp
+++ b/pulp/floonoc/floonoc.hpp
@@ -108,6 +108,9 @@ public:
     // this width so that the bandwidth corresponds to the width.
     uint64_t width;
 
+    // Whether Support Atomics
+    bool atomics; 
+
 private:
     // Callback called when a target request is asynchronously granted after a denied error was
     // reported
diff --git a/pulp/floonoc/floonoc.py b/pulp/floonoc/floonoc.py
index 2aa365c..bb3e393 100644
--- a/pulp/floonoc/floonoc.py
+++ b/pulp/floonoc/floonoc.py
@@ -47,7 +47,7 @@ class FlooNoc2dMesh(gvsoc.systree.Component):
         before the source output queue is stalled.
     """
     def __init__(self, parent: gvsoc.systree.Component, name, width: int,
-            dim_x: int, dim_y:int, ni_outstanding_reqs: int=8, router_input_queue_size: int=2):
+            dim_x: int, dim_y:int, ni_outstanding_reqs: int=8, router_input_queue_size: int=2, atomics: int=0):
         super(FlooNoc2dMesh, self).__init__(parent, name)
 
         self.add_sources([
@@ -64,6 +64,7 @@ class FlooNoc2dMesh(gvsoc.systree.Component):
         self.add_property('dim_x', dim_x)
         self.add_property('dim_y', dim_y)
         self.add_property('router_input_queue_size', router_input_queue_size)
+        self.add_property('atomics', atomics)
 
     def __add_mapping(self, name: str, base: int, size: int, x: int, y: int):
         self.get_property('mappings')[name] =  {'base': base, 'size': size, 'x': x, 'y': y}
diff --git a/pulp/floonoc/floonoc_network_interface.cpp b/pulp/floonoc/floonoc_network_interface.cpp
index 4124c25..f0621e1 100644
--- a/pulp/floonoc/floonoc_network_interface.cpp
+++ b/pulp/floonoc/floonoc_network_interface.cpp
@@ -130,6 +130,11 @@ void NetworkInterface::fsm_handler(vp::Block *__this, vp::ClockEvent *event)
         req->set_size(size);
         req->set_data(_this->pending_burst_data);
         req->set_is_write(burst->get_is_write());
+        if (_this->noc->atomics)
+        {
+            req->set_opcode(burst->get_opcode());
+            req->set_second_data(burst->get_second_data());
+        }
 
         // Get the target entry corresponding to the current base
         Entry *entry = _this->noc->get_entry(base, size);
@@ -174,8 +179,8 @@ void NetworkInterface::fsm_handler(vp::Block *__this, vp::ClockEvent *event)
 
             // And forward to the first router which is at the same position as the network
             // interface
-            _this->trace.msg(vp::Trace::LEVEL_DEBUG, "Injecting request to noc (req: %p, base: 0x%x, size: 0x%x, destination: (%d, %d))\n",
-                req, base, size, entry->x, entry->y);
+            _this->trace.msg(vp::Trace::LEVEL_DEBUG, "Injecting request to noc (req: %p, base: 0x%x, size: 0x%x, op_code: %0d, destination: (%d, %d))\n",
+                req, base, size, req->get_opcode(), entry->x, entry->y);
 
             // Noe that the router may not grant tje request if its input queue is full.
             // In this case we must stall the network interface
diff --git a/pulp/floonoc/floonoc_router.cpp b/pulp/floonoc/floonoc_router.cpp
index 50cb4ac..bc110bf 100644
--- a/pulp/floonoc/floonoc_router.cpp
+++ b/pulp/floonoc/floonoc_router.cpp
@@ -87,7 +87,8 @@ void Router::fsm_handler(vp::Block *__this, vp::ClockEvent *event)
     for (int i=0; i<5; i++)
     {
         vp::Queue *queue = _this->input_queues[queue_index];
-        if (!queue->empty())
+        // if (!queue->empty())
+        if (queue->size())
         {
             vp::IoReq *req = (vp::IoReq *)queue->head();
 
@@ -173,7 +174,7 @@ void Router::fsm_handler(vp::Block *__this, vp::ClockEvent *event)
             // Since we removed a request, check in next cycle if there is another one to handle
             _this->fsm_event.enqueue();
 
-            break;
+            // break;
         }
 
         // If we didn't any ready request, try with next queue
@@ -204,7 +205,7 @@ void Router::send_to_target(vp::IoReq *req, int pos_x, int pos_y)
         req->status = result;
         this->noc->handle_request_end(req);
     }
-    else if (vp::IO_REQ_DENIED)
+    else if (result == vp::IO_REQ_DENIED)
     {
         int queue = this->get_req_queue(pos_x, pos_y);
 
diff --git a/pulp/idma/be/idma_be_axi.cpp b/pulp/idma/be/idma_be_axi.cpp
index 149cb7f..d99b54a 100644
--- a/pulp/idma/be/idma_be_axi.cpp
+++ b/pulp/idma/be/idma_be_axi.cpp
@@ -93,6 +93,14 @@ void IDmaBeAxi::reset(bool active)
         {
             this->pending_bursts.pop();
         }
+        while(this->issued_axi_burst_order_list.size() > 0)
+        {
+            this->issued_axi_burst_order_list.pop();
+        }
+        while(this->OoO_responses_waiting_list.size() > 0)
+        {
+            this->OoO_responses_waiting_list.pop_front();
+        }
 
         // And put back them all as free
         for (vp::IoReq &req: this->bursts)
@@ -181,6 +189,7 @@ void IDmaBeAxi::send_read_burst_to_axi()
 
     // Send to AXI interface
     vp::IoReqStatus status = this->ico_itf.req(req);
+    this->issued_axi_burst_order_list.push(req);
 
     if (status == vp::IoReqStatus::IO_REQ_OK)
     {
@@ -206,10 +215,55 @@ void IDmaBeAxi::read_handle_req_end(vp::IoReq *req)
 {
     // Remember at which timestamp the burst must be notified
     this->read_timestamps[req->id] = this->clock.get_cycles() + req->get_latency();
-    // Queue the requests, they will be notified in order.
-    this->read_waiting_bursts.push(req);
-    // Enqueue fsm event at desired timestamp in case the event is not already enqueued before
-    this->fsm_event.enqueue(std::max(req->get_latency(), (uint64_t)1));
+
+    // Push to OoO_responses_waiting_list
+    this->OoO_responses_waiting_list.push_back(req);
+
+    // Check OoO_responses_waiting_list and order them to read_waiting_bursts
+    std::list<vp::IoReq *>::iterator OoO_iter;
+    while(true){
+        if (this->issued_axi_burst_order_list.size() == 0)
+        {
+            if (this->OoO_responses_waiting_list.size() != 0)
+            {
+                this->trace.msg(vp::Trace::LEVEL_WARNING, "[iDMA ROB] OoO_responses_waiting_list has remaining entry but issued_axi_burst_order_list size is 0\n");
+            } else {
+                break;
+            }
+        }
+
+        if (this->OoO_responses_waiting_list.size() == 0)
+        {
+            break;
+        }
+
+        int matched = 0;
+        vp::IoReq *req_to_check = this->issued_axi_burst_order_list.front();
+        for (OoO_iter = this->OoO_responses_waiting_list.begin(); OoO_iter != this->OoO_responses_waiting_list.end(); ++OoO_iter)
+        {
+            vp::IoReq *req_responsed = *OoO_iter;
+            if (req_to_check == req_responsed)
+            {
+                matched = 1;
+                break;
+            }
+        }
+
+        if (matched == 0)
+        {
+            break;
+        }
+
+        this->issued_axi_burst_order_list.pop();
+        this->read_waiting_bursts.push(req_to_check);
+        this->OoO_responses_waiting_list.erase(OoO_iter);
+    }
+
+    // Enqueue FSM when read_waiting_bursts is not empty
+    if (this->read_waiting_bursts.size() != 0)
+    {
+        this->fsm_event.enqueue(1);
+    }
 }
 
 
@@ -357,29 +411,37 @@ void IDmaBeAxi::fsm_handler(vp::Block *__this, vp::ClockEvent *event)
 
     // In case we have pending read bursts waiting for pushing data, only do it if the backend
     // is ready to accept the data in case the destination is not ready
-    if (_this->read_waiting_bursts.size() != 0 && _this->be->is_ready_to_accept_data())
+    if (_this->read_waiting_bursts.size() != 0 )
     {
-        vp::IoReq *req = _this->read_waiting_bursts.front();
-
-        // Push the data only once the timestamp has expired to take into account the latency
-        // returned when the data was read
-        if (_this->read_timestamps[req->id] <= _this->clock.get_cycles())
+        if (_this->be->is_ready_to_accept_data())
         {
-            // Move the burst to a different queue so that we can free the request when it is
-            // acknowledge
-            _this->read_waiting_bursts.pop();
-            _this->read_bursts_waiting_ack.push(req);
-
-            // Send the data
-            _this->be->write_data(req->get_data(), req->get_size());
-
-            // Trigger again the FSM since we may continue with another transfer
-            _this->fsm_event.enqueue();
+            vp::IoReq *req = _this->read_waiting_bursts.front();
+
+            // Push the data only once the timestamp has expired to take into account the latency
+            // returned when the data was read
+            if (_this->read_timestamps[req->id] <= _this->clock.get_cycles())
+            {
+                // Move the burst to a different queue so that we can free the request when it is
+                // acknowledge
+                _this->read_waiting_bursts.pop();
+                _this->read_bursts_waiting_ack.push(req);
+
+                // Send the data
+                _this->be->write_data(req->get_data(), req->get_size());
+
+                // Trigger again the FSM since we may continue with another transfer
+                _this->fsm_event.enqueue();
+            }
+            else
+            {
+                // Otherwise check again when timetamp is reached
+                _this->fsm_event.enqueue(_this->read_timestamps[req->id] - _this->clock.get_cycles());
+            }
         }
         else
         {
-            // Otherwise check again when timetamp is reached
-            _this->fsm_event.enqueue(_this->read_timestamps[req->id] - _this->clock.get_cycles());
+            // Enqueue FSM when read_waiting_bursts is not empty
+            _this->fsm_event.enqueue(1);
         }
     }
 }
@@ -396,4 +458,4 @@ void IDmaBeAxi::update()
 bool IDmaBeAxi::is_empty()
 {
     return this->pending_bursts.empty();
-}
\ No newline at end of file
+}
diff --git a/pulp/idma/be/idma_be_axi.hpp b/pulp/idma/be/idma_be_axi.hpp
index 211ea51..4f433b6 100644
--- a/pulp/idma/be/idma_be_axi.hpp
+++ b/pulp/idma/be/idma_be_axi.hpp
@@ -21,6 +21,7 @@
 #pragma once
 
 #include <vector>
+#include <list>
 #include <vp/vp.hpp>
 #include <vp/itf/io.hpp>
 #include "../idma.hpp"
@@ -108,4 +109,8 @@ private:
     // Current base of the first transfer. This is when a chunk of data to be written is received
     // to know the base where it should be written.
     uint64_t current_burst_base;
+
+    // Track the orders of DMA issued requests, for dealing with OoO responses
+    std::queue<vp::IoReq *> issued_axi_burst_order_list;
+    std::list<vp::IoReq *> OoO_responses_waiting_list;
 };
diff --git a/pulp/idma/fe/idma_fe_xdma.cpp b/pulp/idma/fe/idma_fe_xdma.cpp
index 867c0e2..f860e33 100644
--- a/pulp/idma/fe/idma_fe_xdma.cpp
+++ b/pulp/idma/fe/idma_fe_xdma.cpp
@@ -46,6 +46,12 @@ IDmaFeXdma::IDmaFeXdma(vp::Component *idma, IdmaTransferConsumer *me)
 
     // Declare offload master interface for granting blocked transfers
     idma->new_master_port("offload_grant", &this->offload_grant_itf, this);
+
+    // track transfer time
+    this->transfer_start_time = 0;
+    this->num_inflight_transfer = 0;
+    this->total_idma_used_time = 0;
+    this->TxnList = "";
 }
 
 
@@ -133,6 +139,14 @@ uint32_t IDmaFeXdma::enqueue_copy(uint32_t config, uint32_t size, bool &granted)
     this->next_transfer_id.set(transfer_id + 1);
 
     this->trace.msg(vp::Trace::LEVEL_TRACE, "Allocated transfer ID (id: %d)\n", transfer_id);
+    std::stringstream ss;
+    ss << "| Txn " << transfer_id << " = {src: 0x" << std::hex << this->src.get() << ", dst: 0x" << std::hex << this->dst.get() << ", size: 0x"<< std::hex << size << " }";
+    this->TxnList += ss.str();
+    if (this->num_inflight_transfer == 0)
+    {
+        this->transfer_start_time = this->time.get_time();
+    }
+    this->num_inflight_transfer += 1;
 
     // Allocate a new transfer and fill it from registers
     IdmaTransfer *transfer = new IdmaTransfer();
@@ -170,6 +184,13 @@ uint32_t IDmaFeXdma::enqueue_copy(uint32_t config, uint32_t size, bool &granted)
 void IDmaFeXdma::ack_transfer(IdmaTransfer *transfer)
 {
     this->completed_id.inc(1);
+    this->num_inflight_transfer -= 1;
+    if (this->num_inflight_transfer == 0)
+    {
+        this->total_idma_used_time += (this->time.get_time() - this->transfer_start_time)/1000;
+        this->trace.msg("[iDMA] Finished : %0d ns ---> %0d ns | period = %0d ns | runtime = %0d ns %s\n", (this->transfer_start_time/1000), (this->time.get_time()/1000), (this->time.get_time() - this->transfer_start_time)/1000, this->total_idma_used_time, this->TxnList.c_str());
+        this->TxnList = "";
+    }
     delete transfer;
 }
 
diff --git a/pulp/idma/fe/idma_fe_xdma.hpp b/pulp/idma/fe/idma_fe_xdma.hpp
index 300ef51..7883152 100644
--- a/pulp/idma/fe/idma_fe_xdma.hpp
+++ b/pulp/idma/fe/idma_fe_xdma.hpp
@@ -20,6 +20,9 @@
 
 #pragma once
 
+#include <string>
+#include <iostream>
+#include <sstream>
 #include <vp/vp.hpp>
 #include <cpu/iss/include/offload.hpp>
 #include <vp/register.hpp>
@@ -82,4 +85,10 @@ private:
     vp::Signal<bool> do_transfer_grant;
     // In case a transfer was blocked, gives the transfer which was blocked
     IdmaTransfer *stalled_transfer;
+
+    //track iDMA transfer time
+    int64_t transfer_start_time;
+    int64_t num_inflight_transfer;
+    int64_t total_idma_used_time;
+    std::string TxnList;
 };
diff --git a/pulp/snitch/sequencer.cpp b/pulp/snitch/sequencer.cpp
index 673529f..080f26f 100644
--- a/pulp/snitch/sequencer.cpp
+++ b/pulp/snitch/sequencer.cpp
@@ -21,7 +21,7 @@
  */
 
 // Temporary workaround to let this component include ISS headers
-#include <../../../../isa_snitch_rv32imfdvca.hpp>
+#include <../../../../isa_snitch_rv32imfdva.hpp>
 
 #include <vp/vp.hpp>
 #include <vp/itf/io.hpp>
diff --git a/pulp/snitch/snitch_core.py b/pulp/snitch/snitch_core.py
index 0bda5e4..b00ea87 100644
--- a/pulp/snitch/snitch_core.py
+++ b/pulp/snitch/snitch_core.py
@@ -86,7 +86,7 @@ class Snitch(cpu.iss.riscv.RiscvCommon):
     def __init__(self,
             parent,
             name,
-            isa: str='rv32imafdc',
+            isa: str='rv32imafd',
             misa: int=None,
             binaries: list=[],
             fetch_enable: bool=False,
@@ -99,7 +99,7 @@ class Snitch(cpu.iss.riscv.RiscvCommon):
 
         if isa_instances.get(isa) is None:
             isa_instance = cpu.iss.isa_gen.isa_riscv_gen.RiscvIsa("snitch_" + isa, isa,
-                extensions=[ Rv32ssr(), Rv32frep(), Xdma(), Xf16(), Xf16alt(), Xf8(), Xfvec(), Xfaux() ] )
+                extensions=[ Rv32ssr(), Rv32frep(), Xdma(), Xf16(), Xf16alt(), Xf8(), Xfvec(), Xfaux(), Rv32redmule() ] )
             add_latencies(isa_instance)
             isa_instances[isa] = isa_instance
 
@@ -150,13 +150,16 @@ class Snitch(cpu.iss.riscv.RiscvCommon):
     def o_BARRIER_REQ(self, itf: gvsoc.systree.SlaveItf):
         self.itf_bind('barrier_req', itf, signature='wire<bool>')
 
+    def o_REDMULE(self, itf: gvsoc.systree.SlaveItf):
+        self.itf_bind('redmule_itf', itf, signature='io')
+
 
 class SnitchBare(cpu.iss.riscv.RiscvCommon):
 
     def __init__(self,
             parent,
             name,
-            isa: str='rv32imafdc',
+            isa: str='rv32imafd',
             misa: int=None,
             binaries: list=[],
             fetch_enable: bool=False,
@@ -197,7 +200,7 @@ class Snitch_fp_ss(cpu.iss.riscv.RiscvCommon):
     def __init__(self,
             parent,
             name,
-            isa: str='rv32imafdc',
+            isa: str='rv32imafd',
             misa: int=None,
             binaries: list=[],
             fetch_enable: bool=False,
@@ -209,7 +212,7 @@ class Snitch_fp_ss(cpu.iss.riscv.RiscvCommon):
 
 
         isa_instance = cpu.iss.isa_gen.isa_riscv_gen.RiscvIsa("snitch_fp_ss_" + isa, isa,
-            extensions=[ Rv32ssr(), Rv32frep(), Xdma(), Xf16(), Xf16alt(), Xf8(), Xfvec(), Xfaux() ] )
+            extensions=[ Rv32ssr(), Rv32frep(), Xdma(), Xf16(), Xf16alt(), Xf8(), Xfvec(), Xfaux(), Rv32redmule() ] )
 
         add_latencies(isa_instance)
 
@@ -266,7 +269,7 @@ class Spatz(cpu.iss.riscv.RiscvCommon):
     def __init__(self,
             parent,
             name,
-            isa: str='rv32imafdc',
+            isa: str='rv32imafd',
             misa: int=None,
             binaries: list=[],
             fetch_enable: bool=False,
diff --git a/pulp/snitch/snitch_isa.py b/pulp/snitch/snitch_isa.py
index 0f1fea3..3f5a975 100644
--- a/pulp/snitch/snitch_isa.py
+++ b/pulp/snitch/snitch_isa.py
@@ -100,3 +100,19 @@ class Rv32ssr(IsaSubset):
             Instr('scfgr', Format_SCFGR, '0000000----- 00001 001 ---- -0101011', tags=["ssr", 'nseq', 'fp_op']),
             Instr('scfgw', Format_SCFGW, '0000000----- ----- 010 0000 00101011', tags=["ssr", 'nseq', 'fp_op']),
         ])
+
+Format_MARITH = [
+    InReg (0, Range(15, 5)),
+    InReg (1, Range(20, 5)),
+    InReg (2, Range(27, 5)),
+    UnsignedImm(0, Range(7, 8)),
+]
+
+
+class Rv32redmule(IsaSubset):
+
+    def __init__(self):
+        super().__init__(name='redmule', instrs=[
+            Instr('mcnfig', Format_R     ,'0000000 ----- ----- 000 00000 0001010'),
+            Instr('marith', Format_MARITH,'-----00 ----- ----- --- ----- 0101010'),
+        ])
